{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLAYP7h42z5b",
        "outputId": "8fade5b3-1ec5-4f37-8a38-a0a306846987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.25.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.11.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.11/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<10,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.5.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: pympler<2,>=0.9 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.18 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: tzlocal<5,>=1.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.3.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.34.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.29.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.21.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.3.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.3.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.18->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.18->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.18->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.18->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.11/dist-packages (from tzlocal<5,>=1.1->streamlit) (0.1.0.post0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (4.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyngrok) (1.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Load the pre-trained models\n",
        "@st.cache_resource\n",
        "def load_image_model():\n",
        "    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False)\n",
        "    model.load_state_dict(torch.load(\"image_classification_model.pt\", map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "@st.cache_resource\n",
        "def load_text_model():\n",
        "    return load_model(\"text_classification_model.h5\")\n",
        "\n",
        "# Load tokenizer and embedding matrix (if needed)\n",
        "tokenizer = joblib.load(\"tokenizer.joblib\")  # Ensure this file exists\n",
        "\n",
        "# Define categories for image classification\n",
        "categories = ['Sports', 'News', 'Sci/Tech', 'Entertainment']\n",
        "\n",
        "# Preprocessing for image classification\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Preprocessing for text classification\n",
        "max_length = 100\n",
        "def preprocess_text(text):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_length)\n",
        "    return padded_seq\n",
        "\n",
        "# Function to classify images\n",
        "def classify_image(image_path, model):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    img_tensor = transform(img).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img_tensor)\n",
        "        _, predicted_idx = torch.max(outputs, 1)\n",
        "\n",
        "    # Fetch the ImageNet labels\n",
        "    labels_url = \"https://raw.githubusercontent.com/JaswanthRemiel/ImageClassificationLABELS/refs/heads/main/imagenet-simple-labels.json\"\n",
        "    labels = requests.get(labels_url).json()\n",
        "    predicted_label = labels[predicted_idx.item()]\n",
        "\n",
        "    # Map the predicted index to one of the predefined categories\n",
        "    mapped_category = categories[predicted_idx.item() % 4]\n",
        "\n",
        "    return f\"Predicted Label: {predicted_label}\", f\"Mapped Category: {mapped_category}\"\n",
        "\n",
        "# Function to classify text\n",
        "def classify_text(text, model):\n",
        "    processed_text = preprocess_text(text)\n",
        "    prediction = model.predict(processed_text)\n",
        "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "    class_mapping = {0: 'Class A', 1: 'Class B', 2: 'Class C', 3: 'Class D'}  # Update with actual classes\n",
        "    return class_mapping[predicted_class]\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"Image and Text Classification App\")\n",
        "\n",
        "option = st.selectbox(\"Choose a task:\", (\"Image Classification\", \"Text Classification\"))\n",
        "\n",
        "if option == \"Image Classification\":\n",
        "    st.header(\"Upload an image for classification\")\n",
        "    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption=\"Uploaded Image.\", use_column_width=True)\n",
        "        if st.button(\"Classify Image\"):\n",
        "            model = load_image_model()\n",
        "            label, category = classify_image(uploaded_file, model)\n",
        "            st.write(label)\n",
        "            st.write(category)\n",
        "\n",
        "elif option == \"Text Classification\":\n",
        "    st.header(\"Enter text for classification\")\n",
        "    user_input = st.text_area(\"Type your text here:\")\n",
        "    if st.button(\"Classify Text\"):\n",
        "        if user_input:\n",
        "            model = load_text_model()\n",
        "            result = classify_text(user_input, model)\n",
        "            st.write(f\"Predicted Class: {result}\")\n",
        "        else:\n",
        "            st.warning(\"Please enter some text.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0_hqn7W3G74",
        "outputId": "56c4a629-c8d4-4161-e6a1-b545b88ce549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Streamlit app code as a string\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "import requests\n",
        "\n",
        "# Load the pre-trained models\n",
        "@st.cache_resource\n",
        "def load_image_model():\n",
        "    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False)\n",
        "    model.load_state_dict(torch.load(\"image_classification_model.pt\", map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "@st.cache_resource\n",
        "def load_text_model():\n",
        "    return load_model(\"text_classification_model.h5\")\n",
        "\n",
        "# Load tokenizer and embedding matrix (if needed)\n",
        "tokenizer = joblib.load(\"tokenizer.joblib\")  # Ensure this file exists\n",
        "\n",
        "# Define categories for image classification\n",
        "categories = ['Sports', 'News', 'Sci/Tech', 'Entertainment']\n",
        "\n",
        "# Preprocessing for image classification\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Preprocessing for text classification\n",
        "max_length = 100\n",
        "def preprocess_text(text):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_length)\n",
        "    return padded_seq\n",
        "\n",
        "# Function to classify images\n",
        "def classify_image(image_path, model):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    img_tensor = transform(img).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img_tensor)\n",
        "        _, predicted_idx = torch.max(outputs, 1)\n",
        "\n",
        "    # Fetch the ImageNet labels\n",
        "    labels_url = \"https://raw.githubusercontent.com/JaswanthRemiel/ImageClassificationLABELS/refs/heads/main/imagenet-simple-labels.json\"\n",
        "    labels = requests.get(labels_url).json()\n",
        "    predicted_label = labels[predicted_idx.item()]\n",
        "\n",
        "    # Map the predicted index to one of the predefined categories\n",
        "    mapped_category = categories[predicted_idx.item() % 4]\n",
        "\n",
        "    return f\"Predicted Label: {predicted_label}\", f\"Mapped Category: {mapped_category}\"\n",
        "\n",
        "# Function to classify text\n",
        "def classify_text(text, model):\n",
        "    processed_text = preprocess_text(text)\n",
        "    prediction = model.predict(processed_text)\n",
        "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "    class_mapping = {0: 'Sports', 1: 'News', 2: 'Sci/Tech', 3: 'Entertainment'}  # Update with actual classes\n",
        "    return class_mapping[predicted_class]\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"Image and Text Classification App\")\n",
        "\n",
        "option = st.selectbox(\"Choose a task:\", (\"Image Classification\", \"Text Classification\"))\n",
        "\n",
        "if option == \"Image Classification\":\n",
        "    st.header(\"Upload an image for classification\")\n",
        "    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption=\"Uploaded Image.\", use_column_width=True)\n",
        "        if st.button(\"Classify Image\"):\n",
        "            model = load_image_model()\n",
        "            label, category = classify_image(uploaded_file, model)\n",
        "            st.write(label)\n",
        "            st.write(category)\n",
        "\n",
        "elif option == \"Text Classification\":\n",
        "    st.header(\"Enter text for classification\")\n",
        "    user_input = st.text_area(\"Type your text here:\")\n",
        "    if st.button(\"Classify Text\"):\n",
        "        if user_input:\n",
        "            model = load_text_model()\n",
        "            result = classify_text(user_input, model)\n",
        "            st.write(f\"Predicted Class: {result}\")\n",
        "        else:\n",
        "            st.warning(\"Please enter some text.\")\n",
        "\"\"\"\n",
        "\n",
        "# Write the Streamlit app code to app.py\n",
        "with open(\"app.py\", \"w\") as file:\n",
        "    file.write(app_code)\n",
        "\n",
        "# Start the Streamlit app in the background\n",
        "!streamlit run app.py &>/dev/null&\n",
        "\n",
        "# Install required libraries\n",
        "!pip install pycloudflared\n",
        "\n",
        "# Import the cloudflared library\n",
        "from pycloudflared import try_cloudflare\n",
        "\n",
        "# Set up Cloudflare tunnel to port 8501 (default Streamlit port)\n",
        "public_url = try_cloudflare(port=8501)\n",
        "\n",
        "# Print the public URL\n",
        "if public_url:\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "else:\n",
        "    print(\"Failed to create a public URL. Please check your setup.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebrun1YJ3Lxm",
        "outputId": "81082db2-833f-459b-8d25-59338baa4800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycloudflared in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pycloudflared) (4.67.1)\n",
            " * Running on https://federal-karen-initiatives-ohio.trycloudflare.com\n",
            " * Traffic stats available on http://127.0.0.1:20241/metrics\n",
            "Public URL: Urls(tunnel='https://federal-karen-initiatives-ohio.trycloudflare.com', metrics='http://127.0.0.1:20241/metrics', process=<Popen: returncode: None args: ['/usr/local/lib/python3.11/dist-packages/pyc...>)\n"
          ]
        }
      ]
    }
  ]
}